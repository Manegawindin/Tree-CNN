{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Input, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining class to support Tree-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN (object):\n",
    "    def __init__(self, num_classes, input_shape):\n",
    "        input_layer, l = self.create_network_base(num_classes, input_shape)\n",
    "        self.num_classes = num_classes\n",
    "        self.input_shape = input_shape\n",
    "        self.model = Model(input_layer, l)\n",
    "        self.model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    def create_network_base(self, num_classes, input_shape):\n",
    "        input_layer = Input(shape=input_shape)\n",
    "        l = Conv2D(16, 3, activation='relu')(input_layer)\n",
    "        l = Conv2D(32, 3, activation='relu')(l)\n",
    "        l = Conv2D(16, 3, activation='relu')(l)\n",
    "        l = Flatten()(l)\n",
    "        l = Dense(512, activation='relu')(l)\n",
    "        l = Dense(num_classes, activation='softmax')(l)\n",
    "        \n",
    "        return input_layer, l\n",
    "    \n",
    "    def train(self, X, Y):\n",
    "        self.model.fit(X, Y, batch_size=16, epochs=2)\n",
    "\n",
    "    def remove_class(self, idx_to_remove):\n",
    "        input_layer, l = self.create_network_base((self.num_classes-1), self.input_shape)\n",
    "        new_model = Model(input_layer, l)\n",
    "        \n",
    "        for idx in range(len(self.model.layers)-1):\n",
    "            if len(self.model.layers[idx].get_weights()) == 0 :\n",
    "                continue\n",
    "            wi = self.model.layers[idx].get_weights()[0]\n",
    "            bi = self.model.layers[idx].get_weights()[1]\n",
    "            new_model.layers[idx].set_weights((wi, bi))\n",
    "        \n",
    "        # Copy a already treined part of last layer\n",
    "        old_w = self.model.layers[-1].get_weights()[0]\n",
    "        new_w = new_model.layers[-1].get_weights()[0]\n",
    "        old_bias = self.model.layers[-1].get_weights()[1]\n",
    "        new_bias = new_model.layers[-1].get_weights()[1]\n",
    "\n",
    "        for i in range(old_w.shape[0]):\n",
    "            aux = 0\n",
    "            for j in range(old_w.shape[1]):\n",
    "                if j != idx_to_remove:\n",
    "                    new_w[i][aux] = old_w[i][j]\n",
    "                    aux = aux + 1\n",
    "        aux = 0\n",
    "        for i in range(old_bias.shape[0]):\n",
    "            if i != idx_to_remove:\n",
    "                new_bias[aux] = old_bias[i]\n",
    "                aux = aux + 1\n",
    "\n",
    "        new_model.layers[-1].set_weights((new_w, new_bias))\n",
    "        \n",
    "        self.model = new_model\n",
    "        self.model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        self.num_classes = self.num_classes - 1\n",
    "        \n",
    "    def add_class(self):\n",
    "        input_layer, l = self.create_network_base((self.num_classes+1), self.input_shape)\n",
    "        new_model = Model(input_layer, l)\n",
    "        \n",
    "        for idx in range(len(self.model.layers)-1):\n",
    "            if len(self.model.layers[idx].get_weights()) == 0 :\n",
    "                continue\n",
    "            wi = self.model.layers[idx].get_weights()[0]\n",
    "            bi = self.model.layers[idx].get_weights()[1]\n",
    "            new_model.layers[idx].set_weights((wi, bi))\n",
    "        \n",
    "        # Copy a already treined part of last layer\n",
    "        old_w = self.model.layers[-1].get_weights()[0]\n",
    "        new_w = new_model.layers[-1].get_weights()[0]\n",
    "        old_bias = self.model.layers[-1].get_weights()[1]\n",
    "        new_bias = new_model.layers[-1].get_weights()[1]\n",
    "\n",
    "        for i in range(old_w.shape[0]):\n",
    "            for j in range(old_w.shape[1]):\n",
    "                new_w[i][j] = old_w[i][j]\n",
    "        for i in range(old_bias.shape[0]):\n",
    "            new_bias[i] = old_bias[i]\n",
    "\n",
    "        new_model.layers[-1].set_weights((new_w, new_bias))\n",
    "        \n",
    "        self.model = new_model\n",
    "        self.model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        self.num_classes = self.num_classes + 1\n",
    "        \n",
    "    def pred(self, img):\n",
    "        return self.model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeList (object):\n",
    "    def __init__(self, label, values, nodes, class_position):\n",
    "        self.label = label\n",
    "        self.values = values\n",
    "        self.nodes = nodes\n",
    "        self.class_position = class_position\n",
    "    def __str__(self):\n",
    "        return {'label': self.label, 'values': self.values, 'nodes':self.nodes, 'class_position': self.class_position}\n",
    "    def __unicode__(self):\n",
    "        return {'label': self.label, 'values': self.values, 'nodes':self.nodes, 'class_position': self.class_position}\n",
    "    def __repr__(self):\n",
    "        return 'label: ' + str(self.label) + ' values: ' + str(self.values) + ' nodes: ' + str(self.nodes)+' class_pos: '+ str(self.class_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnNode (object):\n",
    "    def __init__(self, num_classes, labels = [], max_leafes=10):\n",
    "        self.net = CNN(num_classes, (28,28,1))\n",
    "        self.num_classes = num_classes\n",
    "        self.childrens = [label for label in labels]\n",
    "        self.childrens_leaf = [True for _ in range(num_classes)]\n",
    "        self.labels = labels\n",
    "        self.max_leafes = max_leafes\n",
    "        self.labels_transform = {}\n",
    "        for nc in range(num_classes):\n",
    "            self.labels_transform[nc] = []\n",
    "            self.labels_transform[nc].append(labels[nc])\n",
    "        \n",
    "    \n",
    "    def get_num_leafnodes(self):\n",
    "        count = 0\n",
    "        for is_leaf in self.childrens_leaf:\n",
    "            if is_leaf:\n",
    "                count = count + 1\n",
    "        return count\n",
    "    \n",
    "    def remove_leaf(self, label):\n",
    "        childrens = []\n",
    "        childrens_leaf = []\n",
    "        labels = []\n",
    "        del self.labels_transform[label]\n",
    "        self.num_classes = (self.num_classes - 1)\n",
    "        position_in_net = -1\n",
    "        \n",
    "        for i in range(len(self.labels)):\n",
    "            if self.labels[i] != label:\n",
    "                childrens.append(self.childrens[i])\n",
    "                childrens_leaf.append(self.childrens_leaf[i])\n",
    "                labels.append(self.labels[i])\n",
    "            else:\n",
    "                position_in_net = i\n",
    "                \n",
    "        self.childrens = childrens\n",
    "        self.childrens_leaf = childrens_leaf\n",
    "        self.labels = labels\n",
    "        #TODO: REMOVE in Net the neuron position_in_net of top layer\n",
    "        self.net.remove_class(position_in_net)\n",
    "        \n",
    "    def add_leaf(self, label):\n",
    "        self.childrens.append(label)\n",
    "        self.childrens_leaf.append(True)\n",
    "        self.labels.append(label)\n",
    "        self.labels_transform[label] = []\n",
    "        self.labels_transform[label].append(label)\n",
    "        #TODO: ADD in Net more one neuron in top layer\n",
    "        self.net.add_class()\n",
    "    \n",
    "    def predict(self, imgs):\n",
    "        vector_output = self.net.pred(imgs)\n",
    "        return vector_output\n",
    "    \n",
    "    def inference(self, imgs):\n",
    "        vector_output = self.net.pred(imgs)\n",
    "        out = np.array([idx for idx in np.argmax(vector_output, axis=1)])\n",
    "        output = np.array([-1 for _ in range(imgs.shape[0])])\n",
    "        for i, o in zip(range(len(out)), out):\n",
    "            output[i] = self.labels[o]\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def train(self, X, Y):\n",
    "        #TODO: Use the labels_transform to transform the Y\n",
    "        self.net.train(X, Y)\n",
    "        #TODO: Pass the train to subnodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing CnnNode with 2 nivels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3802768 , 0.30769065, 0.31203258],\n",
       "       [0.38332018, 0.3050918 , 0.311588  ],\n",
       "       [0.3771458 , 0.32205832, 0.30079588],\n",
       "       [0.38218996, 0.2913022 , 0.32650778],\n",
       "       [0.38976935, 0.29702896, 0.31320173]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = np.random.rand(5,28,28,1)\n",
    "cnnNode = CnnNode(3, labels=[2, 3, 8])\n",
    "cnnNodeC = CnnNode(2, labels=[4, 1])\n",
    "cnnNode.childrens.append(cnnNodeC)\n",
    "cnnNode.predict(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeCNN (object):\n",
    "    def __init__(self, num_class_initial, initial_labels, alpha=0.1, beta=0.1, max_leafnodes=1000):\n",
    "        self.root = CnnNode(num_class_initial, labels=initial_labels)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.max_leafnodes = max_leafnodes\n",
    "        \n",
    "    \n",
    "    def addTasks(self, imgs_of_classes=[], labels=[]):\n",
    "        self.growTreeCNN(self.root, imgs_of_classes, labels)\n",
    "        \n",
    "    def train(self, X, Y):\n",
    "        self.root.train(X, Y)\n",
    "        \n",
    "    def inference(self, X):\n",
    "        return self.root.inference(X)\n",
    "        \n",
    "        \n",
    "    def growTreeCNN(self, operation_node, imgs_of_classes=[], labels=[]):\n",
    "        def get_Oavg_matrix(node, imgs_of_classes_, labels_):\n",
    "            Oavg = np.zeros(shape=(node.num_classes, 0))\n",
    "            for imgs, label in zip(imgs_of_classes, labels_):\n",
    "                net_out = node.predict(imgs)\n",
    "                Oavg_i = np.average(net_out, axis=0)\n",
    "                Oavg = np.concatenate(( Oavg, Oavg_i.reshape((Oavg_i.shape[0], 1)) ), axis=1)\n",
    "            return Oavg\n",
    "        \n",
    "        def get_loglikelihood_matrix(Oavg):\n",
    "            return (np.power(np.e, Oavg) / np.sum(np.power(np.e, Oavg), axis=0))\n",
    "        \n",
    "        def generate_listS(llh, labels_in):\n",
    "            listS = []\n",
    "            for i in range(llh.shape[1]):\n",
    "                label = labels_in[i]\n",
    "                values = []\n",
    "                nodes = []\n",
    "\n",
    "                col = llh[:,i].copy()\n",
    "                for _ in range(3):\n",
    "                    max_idx = np.argmax(col)\n",
    "                    values.append(col[max_idx])\n",
    "                    nodes.append(max_idx)\n",
    "                    col[max_idx] = -100\n",
    "\n",
    "                listS.append(NodeList(label, values, nodes, i))\n",
    "\n",
    "            # Sort List S by value of S[i].values[0]\n",
    "            listS.sort(key=lambda node_list: node_list.values[0])\n",
    "            \n",
    "            return listS\n",
    "\n",
    "        llh = get_loglikelihood_matrix(get_Oavg_matrix(operation_node, imgs_of_classes, labels))\n",
    "        \n",
    "        listS = generate_listS(llh, labels)\n",
    "        new_labels = labels\n",
    "        \n",
    "        branches_dest = {}\n",
    "        while len(listS) > 0:\n",
    "            nodeList = listS[0]\n",
    "            rows_to_remove_in_llh = []\n",
    "            if nodeList.values[0] - nodeList.values[1] > self.alpha:\n",
    "                if operation_node.childrens_leaf[nodeList.nodes[0]]:\n",
    "                    operation_node.childrens_leaf[nodeList.nodes[0]] = False\n",
    "                    old_label = operation_node.labels[nodeList.nodes[0]]\n",
    "                    new_label = nodeList.label\n",
    "                    branch_node = CnnNode(2, labels=[old_label, new_label])\n",
    "                    operation_node.childrens[nodeList.nodes[0]] = branch_node\n",
    "                else:\n",
    "                    if nodeList.nodes[0] not in branches_dest:\n",
    "                        branches_dest[nodeList.nodes[0]] = []\n",
    "                    branches_dest[nodeList.nodes[0]].append(nodeList.label)\n",
    "                \n",
    "                operation_node.labels_transform[nodeList.nodes[0]].append(nodeList.label)\n",
    "            elif nodeList.values[1] - nodeList.values[2] > self.beta:\n",
    "                left_is_leafnode = operation_node.childrens_leaf[nodeList.nodes[0]]\n",
    "                right_is_leafnode = operation_node.childrens_leaf[nodeList.nodes[1]]\n",
    "                has_space_in_left = left_is_leafnode or (operation_node.childrens[nodeList.nodes[0]].get_num_leafnodes() < (self.max_leafnodes - 1))\n",
    "                \n",
    "                if right_is_leafnode and has_space_in_left: # if Merge\n",
    "                    if operation_node.childrens_leaf[nodeList.nodes[0]]: # if left is a leaf\n",
    "                        operation_node.childrens_leaf[nodeList.nodes[0]] = False\n",
    "                        old_label = operation_node.labels[nodeList.nodes[0]]\n",
    "                        new_label = operation_node.labels[nodeList.nodes[1]]\n",
    "                        branch_node = CnnNode(2, labels=[old_label, new_label])\n",
    "                        operation_node.childrens[nodeList.nodes[0]] = branch_node\n",
    "                    else:\n",
    "                        operation_node.childrens[nodeList.nodes[0]].add_leaf(operation_node.labels[nodeList.nodes[1]])\n",
    "                        if nodeList.nodes[0] not in branches_dest:\n",
    "                            branches_dest[nodeList.nodes[0]] = []\n",
    "                        branches_dest[nodeList.nodes[0]].append(nodeList.label)\n",
    "                    \n",
    "                    operation_node.labels_transform[nodeList.nodes[0]].append(operation_node.labels[nodeList.nodes[1]])\n",
    "                    operation_node.remove_leaf(operation_node.labels[nodeList.nodes[1]])\n",
    "                    rows_to_remove_in_llh.append(nodeList.nodes[1])\n",
    "                else:\n",
    "                    if left_is_leafnode:\n",
    "                        operation_node.childrens_leaf[nodeList.nodes[0]] = False\n",
    "                        old_label = operation_node.labels[nodeList.nodes[0]]\n",
    "                        new_label = nodeList.label\n",
    "                        branch_node = CnnNode(2, labels=[old_label, new_label])\n",
    "                        operation_node.childrens[nodeList.nodes[0]] = branch_node\n",
    "                    elif right_is_leafnode:\n",
    "                        operation_node.childrens_leaf[nodeList.nodes[1]] = False\n",
    "                        old_label = operation_node.labels[nodeList.nodes[1]]\n",
    "                        new_label = nodeList.label\n",
    "                        branch_node = CnnNode(2, labels=[old_label, new_label])\n",
    "                        operation_node.childrens[nodeList.nodes[1]] = branch_node\n",
    "                    else:\n",
    "                        if operation_node.childrens[nodeList.nodes[0]].get_num_leafnodes() < operation_node.childrens[nodeList.nodes[1]].get_num_leafnodes():\n",
    "                            if nodeList.nodes[0] not in branches_dest:\n",
    "                                branches_dest[nodeList.nodes[0]] = []\n",
    "                            branches_dest[nodeList.nodes[0]].append(nodeList.label)\n",
    "                        else:\n",
    "                            if nodeList.nodes[1] not in branches_dest:\n",
    "                                branches_dest[nodeList.nodes[1]] = []\n",
    "                                print(nodeList)\n",
    "                            branches_dest[nodeList.nodes[1]].append(nodeList.label)\n",
    "                    \n",
    "            else:\n",
    "                operation_node.add_leaf(nodeList.label)\n",
    "                \n",
    "            \n",
    "            # Clean likelihood matrix and labels to recreate listS to next iteration\n",
    "            # Delete column already inserted\n",
    "            llh = np.delete(llh, nodeList.class_position, axis=1)\n",
    "            # Delete rows that was merged\n",
    "            for r in rows_to_remove_in_llh:\n",
    "                llh = np.delete(llh, r, axis=0)\n",
    "            # Delete rows that represent full nodes (just branch/child nodes)\n",
    "            deleted = 0\n",
    "            for i in range(len(operation_node.childrens_leaf)):\n",
    "                if not operation_node.childrens_leaf[i] and (operation_node.childrens[i].get_num_leafnodes() >= self.max_leafnodes):\n",
    "                    llh = np.delete(llh, (i - deleted), axis=0)\n",
    "                    deleted = deleted + 1\n",
    "            # Update labels\n",
    "            del new_labels[nodeList.class_position]\n",
    "            listS = generate_listS(llh, new_labels)\n",
    "        \n",
    "        # Send to sub-nivels\n",
    "        for k, v in branches_dest.items():\n",
    "            imgs_to_send = []\n",
    "            labels_to_send = []\n",
    "            for idx, label in zip(range(len(labels)), labels):\n",
    "                if label in v:\n",
    "                    imgs_to_send.append(imgs_of_classes[idx])\n",
    "                    labels_to_send.append(labels[idx])\n",
    "\n",
    "            print(idx_to_send)\n",
    "            self.growTreeCNN(operation_node.childrens[k], imgs_to_send, labels_to_send)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = TreeCNN(3, [0,1,2,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_classes_X = x_train[y_train<3].astype(float)\n",
    "old_classes_X = old_classes_X.reshape((old_classes_X.shape[0], old_classes_X.shape[1], old_classes_X.shape[2], 1))\n",
    "old_classes_Y = pd.get_dummies(pd.Series(y_train[y_train<3])).values\n",
    "\n",
    "new_classes_X = [x_train[y_train==i].reshape((x_train[y_train==i].shape[0], x_train[y_train==i].shape[1], x_train[y_train==i].shape[2], 1 )).astype(float) for i in range(4, 7)]\n",
    "new_classes_Y = [pd.get_dummies(pd.Series(y_train[y_train==i])) for i in range(4, 7)]\n",
    "# pd.get_dummies(pd.Series(old_classes_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat = tree.inference(old_classes_X)\n",
    "Y_true = y_train[y_train<3]\n",
    "Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3761477742576384"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y_true==Y_hat)/len(Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18623 samples\n",
      "Epoch 1/2\n",
      "18623/18623 [==============================] - 21s 1ms/sample - loss: 5.3284 - accuracy: 0.8377\n",
      "Epoch 2/2\n",
      "18623/18623 [==============================] - 20s 1ms/sample - loss: 0.0290 - accuracy: 0.9908\n"
     ]
    }
   ],
   "source": [
    "tree.train(old_classes_X, old_classes_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 0, 2, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat = tree.inference(old_classes_X)\n",
    "Y_true = y_train[y_train<3]\n",
    "Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9959190248617301"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y_true==Y_hat)/len(Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Growing network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.addTasks(new_classes_X, [i for i in range(4, 7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.root.net.model.layers[-1].output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.root.childrens[0].childrens_leaf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
